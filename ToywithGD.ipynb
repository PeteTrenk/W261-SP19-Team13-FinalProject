{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression on Toy Data Set with Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#pyspark dependencies\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "from pyspark.sql import SQLContext, functions as f\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"toy\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "#setting schema and reading in pre-processed data to pyspark dataframe\n",
    "intFeatures = ['intFeature1','intFeature2','intFeature3','intFeature4']\n",
    "catFeatures = ['catFeature5','catFeature6']\n",
    "outcomeField = [StructField(\"click\", IntegerType(), True)]\n",
    "quantFields = [StructField(f, DoubleType(), True) for f in intFeatures]\n",
    "qualFields = [StructField(f, StringType(), True) for f in catFeatures]\n",
    "schema = StructType(outcomeField + quantFields + qualFields)\n",
    "\n",
    "toyDf = spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(\"Toy/toySample/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+--------------------+--------------------+--------------------+-----------+-----------+\n",
      "|click|        intFeature1|         intFeature2|         intFeature3|         intFeature4|catFeature5|catFeature6|\n",
      "+-----+-------------------+--------------------+--------------------+--------------------+-----------+-----------+\n",
      "|    0|0.38044728201922134|  1.0461280017194063|  0.8317161330745142|  0.3659735546106383|   25c83c98|   6f6d9be8|\n",
      "|    1|0.38044728201922134| -1.2072044937875812| -1.0969510532590658|  -0.808690496702659|   25c83c98|   7e0ccccf|\n",
      "|    0|0.38044728201922134| -1.2072044937875812|  1.7753909926499136|  0.3659735546106383|   25c83c98|   fbad5c96|\n",
      "|    0|-1.3933721049834424| -1.2072044937875812|  1.9415838693847296|   1.681697323928138|   25c83c98|   7e0ccccf|\n",
      "|    1|-1.3933721049834424| -1.2072044937875812|  1.1861284542225656|   1.681697323928138|   384874ce|   7e0ccccf|\n",
      "|    1|-0.5064624114821106| -1.2072044937875812|  0.7709669997151446|0.021438776840939814|   25c83c98|   7e0ccccf|\n",
      "|    0|-0.5064624114821106| -0.8792259093197071|  0.8018840847466963|  0.5070332726148404|   43b19349|  NA_Bucket|\n",
      "|    1| 1.2673569755205532| -0.6873707363663946|-0.37664099210799884| 0.20605323600656728|   25c83c98|   fbad5c96|\n",
      "|    0|-1.3933721049834424|-0.16753697894520792| -1.0969510532590658|  0.6332154901527597|   25c83c98|   fe6b92e5|\n",
      "|    1| 0.6659684299852395| 0.23338155706897726|  0.8317161330745142|  0.3659735546106383|   25c83c98|   fbad5c96|\n",
      "|    0|0.38044728201922134|  0.5262942442982196| -0.5076885148317183|  2.1672918197020383|   25c83c98|   7e0ccccf|\n",
      "|    0|0.38044728201922134|  1.8494483761453233| -1.0969510532590658| -1.2942849924765598|   25c83c98|   fbad5c96|\n",
      "|    1|-1.3933721049834424|  1.0461280017194063|  0.8317161330745142|  0.3659735546106383|   25c83c98|   fbad5c96|\n",
      "|    0|-1.3933721049834424| -1.2072044937875812| 0.21262154631934865|0.021438776840939814|   25c83c98|   fbad5c96|\n",
      "|    0|-0.5064624114821106| -1.2072044937875812| -0.5076885148317183|-0.19691378339083973|   43b19349|  NA_Bucket|\n",
      "|    0|0.38044728201922134| -0.8792259093197071| -1.4416475413188234|   1.730586699238479|   25c83c98|  NA_Bucket|\n",
      "|    1|0.38044728201922134| -0.6873707363663946| -1.0969510532590658|  0.3659735546106383|   25c83c98|   7e0ccccf|\n",
      "|    0|-1.3933721049834424|-0.16753697894520792|  0.8317161330745142|  -0.808690496702659|   25c83c98|   7e0ccccf|\n",
      "|    0|0.38044728201922134|  0.2965650170372276|  0.8317161330745142| -0.4641557189329606|   25c83c98|   fe6b92e5|\n",
      "|    0|-1.3933721049834424|  1.0254621375192867|  0.8317161330745142| -1.2942849924765598|   25c83c98|   fe6b92e5|\n",
      "+-----+-------------------+--------------------+--------------------+--------------------+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toyDf.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHotEncoder(dataframe,columns):\n",
    "    '''takes a dataframe and corresponding list of columns\n",
    "    to one-hot encode'''\n",
    "    for c in columns:\n",
    "        # collect unique levels in category\n",
    "        levels = dataframe.select(c).distinct().rdd.flatMap(lambda x: x).collect()\n",
    "        #generate dummy variables and associated values\n",
    "        dummy_vals = [f.when(f.col(c) == level, 1).otherwise(0).alias(\"encoded_\" + level) for level in levels]\n",
    "        #update dataframe with new dummy columns (indicator features)\n",
    "        \n",
    "        dataframe = dataframe.select('*',*dummy_vals)\n",
    "    #drop unencoded categorical columns from dataframe    \n",
    "    dataframe = dataframe.drop(*columns)\n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are now 42 columns\n"
     ]
    }
   ],
   "source": [
    "#encode all categorical columns\n",
    "categories = [c for c in toyDf.columns if 'cat' in c]\n",
    "toy_df_encoded = OneHotEncoder(toyDf,categories)\n",
    "print('there are now ' + str(len(toy_df_encoded.columns)) + ' columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+------------------+------------------+------------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+-------------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+-----------------+----------------+----------------+----------------+----------------+----------------+\n",
      "|click|        intFeature1|       intFeature2|       intFeature3|       intFeature4|encoded_bf9f7f48|encoded_5a3e1872|encoded_65be028e|encoded_2c6b8ded|encoded_89ff5705|encoded_3a136cf2|encoded_43b19349|encoded_afcf7897|encoded_f3474129|encoded_Rare_Bucket|encoded_b2241560|encoded_db844843|encoded_25c83c98|encoded_4f8b7acc|encoded_30903e74|encoded_a93acb09|encoded_384874ce|encoded_f281d2a7|encoded_b706ee81|encoded_0942e0a7|encoded_8c837181|encoded_b0530c50|encoded_d5b7606b|encoded_4cf72387|encoded_229df405|encoded_307e775a|encoded_4ea20c7d|encoded_a9411994|encoded_f1d40cbe|encoded_fbad5c96|encoded_3bf701e7|encoded_NA_Bucket|encoded_f1f2de2d|encoded_6f6d9be8|encoded_13718bbd|encoded_fe6b92e5|encoded_7e0ccccf|\n",
      "+-----+-------------------+------------------+------------------+------------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+-------------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+-----------------+----------------+----------------+----------------+----------------+----------------+\n",
      "|    0|0.38044728201922134|1.0461280017194063|0.8317161330745142|0.3659735546106383|               0|               0|               0|               0|               0|               0|               0|               0|               0|                  0|               0|               0|               1|               0|               0|               0|               0|               0|               0|               0|               0|               0|               0|               0|               0|               0|               0|               0|               0|               0|               0|                0|               0|               1|               0|               0|               0|\n",
      "+-----+-------------------+------------------+------------------+------------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+-------------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+-----------------+----------------+----------------+----------------+----------------+----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#notice sparsity from dummy variables\n",
    "toy_df_encoded.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dataframe to RDD\n",
    "toyRDD = toy_df_encoded.rdd.map(lambda x: (x[0],x[1:])).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting coefficient of the \"bias\" as the mean click rate\n",
    "meanClick = toyRDD.map(lambda x: (x[0])).mean()\n",
    "feature_cols = len(toyRDD.take(1)[0][1])\n",
    "coefs = np.array([meanClick] + [0.0]*(feature_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogLoss(RDD,W):\n",
    "    \"\"\"\n",
    "    augments rdd and returns log loss\n",
    "    - why we augment: add a vector \n",
    "    entry of 1 to correspond with the bias term \n",
    "    so that we can apply the model to the data point \n",
    "    using vector multiplication without the added \n",
    "    step of adding the bias.\n",
    "    \n",
    "    Args:\n",
    "        dataframe - columns (target,features...)\n",
    "        W       - (array) model coefficients with bias at index 0\n",
    "    \n",
    "    Reference\n",
    "        def sigmoid(z):\n",
    "            return 1 / (1 + np.exp(-z))\n",
    "        z = np.dot(X, theta)\n",
    "        h = sigmoid(z)\n",
    "        def loss(h, y):\n",
    "            return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "    \"\"\"\n",
    "    #helper function to compute sigmoid\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    #generate augmented rdd of (features,target)\n",
    "    \n",
    "    augmentedData = RDD.map(lambda x: (np.append([1.0],x[1:]),x[0]))\n",
    "    \n",
    "    log_loss = augmentedData \\\n",
    "    .map(lambda x: (np.dot(x[0],W),x[1])) \\\n",
    "    .map(lambda x: (sigmoid(x[0]),x[1])) \\\n",
    "    .map(lambda x: (-x[1]*np.log(x[0]) - (1-x[1])*np.log(1-x[0]))) \\\n",
    "    .mean()\n",
    "    \n",
    "    return log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7644838394523965"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogLoss(toyRDD,coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = sc.broadcast(toyRDD.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform a single GD step\n",
    "def GDUpdate(RDD, W, learningRate = 0.1):\n",
    "    \"\"\"\n",
    "    Perform one OLS gradient descent step/update.\n",
    "    Args:\n",
    "        dataRDD - records are tuples of (features_array, y)\n",
    "        W       - (array) model coefficients with bias at index 0\n",
    "    Returns:\n",
    "        new_model - (array) updated coefficients, bias at index 0\n",
    "        \n",
    "    Reference: gradient = np.dot(X.T, (h - y)) / num_observations\n",
    "        - see above LogLoss function for definition of h and y\n",
    "    \"\"\"\n",
    "    # add a bias 'feature' of 1 at index 0 and convert to array\n",
    "    \n",
    "    #generate augmented rdd of (features,target)\n",
    "    augmentedData = RDD.map(lambda x: (np.append([1.0],x[1:]),x[0]))\n",
    "    \n",
    "    #helper function to compute sigmoid\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    #calculate gradient\n",
    "    getVals = augmentedData \\\n",
    "            .map(lambda x: (np.dot(x[0],W),x[0],x[1])) \\\n",
    "            .map(lambda x: (sigmoid(x[0]),x[1],x[2])) \\\n",
    "            .collect()\n",
    "    \n",
    "    features = []\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    for v in getVals:\n",
    "        features.append(v[1])\n",
    "        predictions.append(v[0])\n",
    "        labels.append(v[2])\n",
    "    \n",
    "    f = np.transpose(features)\n",
    "    l = np.array(labels)\n",
    "    p = np.array(predictions)\n",
    "    \n",
    "    gradient = np.dot(f,(p-l))/N.value\n",
    "    \n",
    "    #apply learning rate to gradient and generate new coefficients\n",
    "    update = np.multiply(gradient,learningRate)\n",
    "    \n",
    "    #original model is the bias + assigned coefficients; update the model with the adjusted coefficients\n",
    "    new_model = W - update\n",
    "    ################## (END) YOUR CODE ################# \n",
    "   \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE:  Loss = 0.7644838394523965\n",
      "----------\n",
      "STEP: 1\n",
      "Loss: 0.7496780805769259\n",
      "Model: [0.248, 0.003, 0.004, -0.0, -0.002, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.002, 0.0, -0.0, -0.0, -0.0, -0.0, -0.02, -0.0, -0.0, -0.0, -0.001, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.004, -0.0, -0.0, -0.0, -0.0, -0.0, -0.006, -0.001, -0.003, 0.0, -0.001, -0.001, -0.006, -0.011]\n",
      "----------\n",
      "STEP: 2\n",
      "Loss: 0.7361257669189284\n",
      "Model: [0.22, 0.006, 0.008, -0.001, -0.004, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.005, 0.0, -0.0, -0.0, -0.0, -0.0, -0.039, -0.0, -0.001, -0.0, -0.002, -0.0, -0.0, -0.001, -0.0, -0.0, -0.0, -0.007, -0.0, -0.0, -0.0, -0.0, -0.0, -0.012, -0.001, -0.007, 0.0, -0.002, -0.002, -0.012, -0.021]\n",
      "----------\n",
      "STEP: 3\n",
      "Loss: 0.723726355267796\n",
      "Model: [0.194, 0.009, 0.012, -0.001, -0.007, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.007, 0.0, -0.0, -0.0, -0.001, -0.0, -0.057, -0.0, -0.001, -0.0, -0.003, -0.0, -0.0, -0.001, -0.0, -0.001, -0.0, -0.011, -0.0, -0.0, -0.0, -0.0, -0.0, -0.018, -0.002, -0.01, 0.0, -0.003, -0.003, -0.018, -0.031]\n",
      "----------\n",
      "STEP: 4\n",
      "Loss: 0.7123852346752154\n",
      "Model: [0.168, 0.011, 0.016, -0.002, -0.009, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.009, 0.0, -0.001, -0.0, -0.001, -0.0, -0.075, -0.0, -0.001, -0.0, -0.004, -0.001, -0.0, -0.001, -0.0, -0.001, -0.0, -0.014, -0.0, -0.001, -0.0, -0.0, -0.0, -0.024, -0.002, -0.013, 0.0, -0.004, -0.003, -0.023, -0.041]\n",
      "----------\n",
      "STEP: 5\n",
      "Loss: 0.7020139073112599\n",
      "Model: [0.144, 0.014, 0.02, -0.002, -0.011, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.011, 0.0, -0.001, -0.0, -0.001, -0.0, -0.091, -0.0, -0.001, -0.0, -0.005, -0.001, -0.001, -0.001, -0.0, -0.001, -0.0, -0.017, -0.0, -0.001, -0.0, -0.0, -0.0, -0.029, -0.002, -0.016, 0.0, -0.004, -0.004, -0.028, -0.05]\n",
      "----------\n",
      "STEP: 6\n",
      "Loss: 0.692530018417839\n",
      "Model: [0.12, 0.017, 0.023, -0.002, -0.013, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.013, 0.0, -0.001, -0.0, -0.001, -0.0, -0.107, -0.0, -0.002, -0.0, -0.006, -0.001, -0.001, -0.002, -0.0, -0.001, -0.0, -0.02, -0.0, -0.001, -0.0, -0.0, -0.0, -0.034, -0.003, -0.019, 0.0, -0.005, -0.005, -0.033, -0.058]\n",
      "----------\n",
      "STEP: 7\n",
      "Loss: 0.6838572672946227\n",
      "Model: [0.098, 0.019, 0.027, -0.003, -0.015, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.015, 0.0, -0.001, -0.0, -0.002, -0.0, -0.122, -0.001, -0.002, -0.0, -0.007, -0.001, -0.001, -0.002, -0.0, -0.001, -0.0, -0.023, -0.0, -0.001, -0.0, -0.0, -0.0, -0.039, -0.003, -0.022, 0.0, -0.006, -0.005, -0.038, -0.067]\n",
      "----------\n",
      "STEP: 8\n",
      "Loss: 0.6759252279409276\n",
      "Model: [0.076, 0.021, 0.03, -0.003, -0.017, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.017, 0.0, -0.001, -0.0, -0.002, -0.0, -0.136, -0.001, -0.002, -0.0, -0.008, -0.001, -0.001, -0.002, -0.0, -0.002, -0.0, -0.025, -0.0, -0.001, -0.0, -0.0, -0.0, -0.044, -0.004, -0.024, 0.0, -0.007, -0.006, -0.042, -0.074]\n",
      "----------\n",
      "STEP: 9\n",
      "Loss: 0.6686691041411001\n",
      "Model: [0.056, 0.024, 0.034, -0.004, -0.019, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.019, 0.0, -0.001, -0.0, -0.002, -0.0, -0.15, -0.001, -0.002, -0.0, -0.009, -0.001, -0.001, -0.002, -0.0, -0.002, -0.0, -0.028, -0.0, -0.001, -0.0, -0.0, -0.0, -0.049, -0.004, -0.027, 0.0, -0.007, -0.007, -0.047, -0.082]\n",
      "----------\n",
      "STEP: 10\n",
      "Loss: 0.6620294398267623\n",
      "Model: [0.036, 0.026, 0.037, -0.004, -0.021, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.02, 0.0, -0.001, -0.0, -0.002, -0.0, -0.163, -0.001, -0.002, -0.0, -0.01, -0.001, -0.001, -0.003, -0.0, -0.002, -0.0, -0.03, -0.0, -0.002, -0.0, -0.0, -0.001, -0.053, -0.005, -0.029, 0.0, -0.008, -0.007, -0.051, -0.089]\n",
      "----------\n",
      "STEP: 11\n",
      "Loss: 0.6559518017538912\n",
      "Model: [0.017, 0.028, 0.04, -0.004, -0.023, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.022, 0.0, -0.001, -0.0, -0.002, -0.0, -0.175, -0.001, -0.002, -0.0, -0.01, -0.002, -0.001, -0.003, -0.0, -0.002, -0.0, -0.033, -0.0, -0.002, -0.0, -0.0, -0.001, -0.057, -0.005, -0.031, 0.0, -0.009, -0.008, -0.055, -0.096]\n",
      "----------\n",
      "STEP: 12\n",
      "Loss: 0.6503864480664633\n",
      "Model: [-0.001, 0.03, 0.043, -0.005, -0.025, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.024, 0.0, -0.002, -0.0, -0.003, -0.0, -0.187, -0.001, -0.003, -0.0, -0.011, -0.002, -0.001, -0.003, -0.0, -0.002, -0.0, -0.035, -0.0, -0.002, -0.0, -0.0, -0.001, -0.061, -0.005, -0.034, 0.0, -0.009, -0.009, -0.059, -0.102]\n",
      "----------\n",
      "STEP: 13\n",
      "Loss: 0.6452879932698382\n",
      "Model: [-0.018, 0.032, 0.046, -0.005, -0.026, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.026, 0.0, -0.002, -0.0, -0.003, -0.0, -0.199, -0.001, -0.003, -0.0, -0.012, -0.002, -0.001, -0.003, -0.0, -0.002, -0.0, -0.037, -0.0, -0.002, -0.0, -0.0, -0.001, -0.065, -0.006, -0.036, 0.0, -0.01, -0.009, -0.062, -0.108]\n",
      "----------\n",
      "STEP: 14\n",
      "Loss: 0.6406150775361227\n",
      "Model: [-0.035, 0.033, 0.049, -0.005, -0.028, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.027, 0.0, -0.002, -0.0, -0.003, -0.0, -0.209, -0.001, -0.003, -0.0, -0.013, -0.002, -0.001, -0.003, -0.0, -0.003, -0.0, -0.039, -0.0, -0.002, -0.0, -0.0, -0.001, -0.069, -0.006, -0.038, 0.0, -0.01, -0.01, -0.066, -0.114]\n",
      "----------\n",
      "STEP: 15\n",
      "Loss: 0.6363300461009596\n",
      "Model: [-0.05, 0.035, 0.052, -0.006, -0.03, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.029, 0.0, -0.002, -0.0, -0.003, -0.0, -0.22, -0.001, -0.003, -0.0, -0.013, -0.002, -0.001, -0.004, -0.0, -0.003, -0.0, -0.041, -0.0, -0.002, -0.0, -0.0, -0.001, -0.072, -0.006, -0.04, 0.0, -0.011, -0.01, -0.069, -0.12]\n",
      "----------\n",
      "STEP: 16\n",
      "Loss: 0.6323986427534989\n",
      "Model: [-0.066, 0.037, 0.055, -0.006, -0.032, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.031, 0.0, -0.002, -0.0, -0.003, -0.0, -0.229, -0.001, -0.003, -0.0, -0.014, -0.002, -0.002, -0.004, -0.0, -0.003, -0.0, -0.043, -0.0, -0.002, -0.0, -0.0, -0.001, -0.076, -0.007, -0.042, 0.0, -0.011, -0.011, -0.072, -0.125]\n",
      "----------\n",
      "STEP: 17\n",
      "Loss: 0.6287897200228526\n",
      "Model: [-0.08, 0.039, 0.058, -0.006, -0.033, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.032, 0.0, -0.002, -0.0, -0.003, -0.0, -0.239, -0.001, -0.003, -0.0, -0.015, -0.002, -0.002, -0.004, -0.0, -0.003, -0.0, -0.045, -0.0, -0.003, -0.0, -0.0, -0.001, -0.079, -0.007, -0.044, 0.0, -0.012, -0.011, -0.076, -0.13]\n",
      "----------\n",
      "STEP: 18\n",
      "Loss: 0.625474967574834\n",
      "Model: [-0.094, 0.04, 0.061, -0.007, -0.035, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.034, 0.0, -0.002, -0.0, -0.004, -0.0, -0.247, -0.001, -0.003, -0.0, -0.015, -0.002, -0.002, -0.004, -0.0, -0.003, -0.0, -0.046, -0.0, -0.003, -0.0, -0.0, -0.001, -0.082, -0.007, -0.045, 0.0, -0.012, -0.011, -0.079, -0.135]\n",
      "----------\n",
      "STEP: 19\n",
      "Loss: 0.6224286595022506\n",
      "Model: [-0.108, 0.042, 0.063, -0.007, -0.037, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.035, 0.0, -0.002, -0.0, -0.004, -0.0, -0.256, -0.001, -0.003, -0.0, -0.016, -0.002, -0.002, -0.004, -0.0, -0.003, -0.0, -0.048, -0.0, -0.003, -0.0, -0.0, -0.001, -0.085, -0.008, -0.047, 0.0, -0.013, -0.012, -0.081, -0.14]\n",
      "----------\n",
      "STEP: 20\n",
      "Loss: 0.6196274205740071\n",
      "Model: [-0.121, 0.043, 0.066, -0.007, -0.038, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.037, 0.0, -0.002, -0.0, -0.004, -0.0, -0.264, -0.001, -0.004, -0.0, -0.017, -0.002, -0.002, -0.004, -0.0, -0.003, -0.0, -0.049, -0.0, -0.003, -0.0, -0.0, -0.001, -0.088, -0.008, -0.049, 0.0, -0.013, -0.012, -0.084, -0.144]\n",
      "----------\n",
      "STEP: 21\n",
      "Loss: 0.6170500110614643\n",
      "Model: [-0.133, 0.045, 0.068, -0.008, -0.04, 0.001, 0.001, -0.001, -0.001, -0.001, 0.0, -0.038, 0.001, -0.003, -0.0, -0.004, -0.001, -0.272, -0.002, -0.004, -0.001, -0.017, -0.002, -0.002, -0.005, -0.0, -0.004, -0.001, -0.051, -0.0, -0.003, -0.0, -0.0, -0.001, -0.091, -0.008, -0.05, 0.001, -0.014, -0.013, -0.087, -0.148]\n",
      "----------\n",
      "STEP: 22\n",
      "Loss: 0.6146771294492114\n",
      "Model: [-0.145, 0.046, 0.071, -0.008, -0.041, 0.001, 0.001, -0.001, -0.001, -0.001, 0.001, -0.04, 0.001, -0.003, -0.001, -0.004, -0.001, -0.279, -0.002, -0.004, -0.001, -0.018, -0.003, -0.002, -0.005, -0.001, -0.004, -0.001, -0.052, -0.0, -0.003, -0.0, -0.001, -0.001, -0.093, -0.009, -0.052, 0.001, -0.014, -0.013, -0.089, -0.152]\n",
      "----------\n",
      "STEP: 23\n",
      "Loss: 0.6124912321316263\n",
      "Model: [-0.156, 0.048, 0.073, -0.008, -0.043, 0.001, 0.001, -0.001, -0.001, -0.001, 0.001, -0.041, 0.001, -0.003, -0.001, -0.004, -0.001, -0.286, -0.002, -0.004, -0.001, -0.019, -0.003, -0.002, -0.005, -0.001, -0.004, -0.001, -0.054, -0.0, -0.003, -0.0, -0.001, -0.001, -0.096, -0.009, -0.053, 0.001, -0.015, -0.013, -0.092, -0.156]\n",
      "----------\n",
      "STEP: 24\n",
      "Loss: 0.6104763690716175\n",
      "Model: [-0.167, 0.049, 0.076, -0.008, -0.044, 0.001, 0.001, -0.001, -0.001, -0.001, 0.001, -0.042, 0.001, -0.003, -0.001, -0.004, -0.001, -0.292, -0.002, -0.004, -0.001, -0.019, -0.003, -0.002, -0.005, -0.001, -0.004, -0.001, -0.055, 0.0, -0.003, -0.0, -0.001, -0.001, -0.098, -0.009, -0.055, 0.001, -0.015, -0.014, -0.094, -0.16]\n",
      "----------\n",
      "STEP: 25\n",
      "Loss: 0.6086180343336756\n",
      "Model: [-0.178, 0.05, 0.078, -0.009, -0.046, 0.001, 0.001, -0.001, -0.001, -0.001, 0.001, -0.044, 0.001, -0.003, -0.001, -0.005, -0.001, -0.299, -0.002, -0.004, -0.001, -0.02, -0.003, -0.002, -0.005, -0.001, -0.004, -0.001, -0.056, 0.0, -0.004, -0.0, -0.001, -0.001, -0.101, -0.009, -0.056, 0.001, -0.015, -0.014, -0.097, -0.163]\n",
      "----------\n",
      "STEP: 26\n",
      "Loss: 0.6069030303838352\n",
      "Model: [-0.188, 0.052, 0.08, -0.009, -0.047, 0.001, 0.001, -0.001, -0.001, -0.001, 0.001, -0.045, 0.001, -0.003, -0.001, -0.005, -0.001, -0.305, -0.002, -0.004, -0.001, -0.02, -0.003, -0.002, -0.005, -0.001, -0.004, -0.001, -0.057, 0.0, -0.004, 0.0, -0.001, -0.001, -0.103, -0.01, -0.057, 0.001, -0.016, -0.014, -0.099, -0.167]\n",
      "----------\n",
      "STEP: 27\n",
      "Loss: 0.6053193450617754\n",
      "Model: [-0.197, 0.053, 0.083, -0.009, -0.049, 0.001, 0.001, -0.001, -0.001, -0.001, 0.001, -0.046, 0.001, -0.003, -0.001, -0.005, -0.001, -0.311, -0.002, -0.004, -0.001, -0.021, -0.003, -0.003, -0.005, -0.001, -0.004, -0.001, -0.058, 0.0, -0.004, 0.0, -0.001, -0.001, -0.105, -0.01, -0.059, 0.001, -0.016, -0.015, -0.101, -0.17]\n",
      "----------\n",
      "STEP: 28\n",
      "Loss: 0.6038560401652261\n",
      "Model: [-0.207, 0.054, 0.085, -0.01, -0.05, 0.001, 0.001, -0.001, -0.001, -0.001, 0.001, -0.048, 0.001, -0.003, -0.001, -0.005, -0.001, -0.316, -0.002, -0.004, -0.001, -0.021, -0.003, -0.003, -0.005, -0.001, -0.004, -0.001, -0.059, 0.0, -0.004, 0.0, -0.001, -0.001, -0.107, -0.01, -0.06, 0.001, -0.016, -0.015, -0.103, -0.173]\n",
      "----------\n",
      "STEP: 29\n",
      "Loss: 0.6025031506366809\n",
      "Model: [-0.216, 0.055, 0.087, -0.01, -0.052, 0.001, 0.001, -0.001, -0.001, -0.001, 0.001, -0.049, 0.001, -0.003, -0.001, -0.005, -0.001, -0.321, -0.002, -0.004, -0.001, -0.022, -0.003, -0.003, -0.006, -0.001, -0.005, -0.001, -0.061, 0.0, -0.004, 0.0, -0.001, -0.001, -0.109, -0.01, -0.061, 0.001, -0.017, -0.015, -0.105, -0.176]\n",
      "----------\n",
      "STEP: 30\n",
      "Loss: 0.6012515934013961\n",
      "Model: [-0.224, 0.056, 0.089, -0.01, -0.053, 0.001, 0.001, -0.001, -0.001, -0.001, 0.001, -0.05, 0.001, -0.003, -0.001, -0.005, -0.001, -0.326, -0.002, -0.004, -0.001, -0.022, -0.003, -0.003, -0.006, -0.001, -0.005, -0.001, -0.061, 0.0, -0.004, 0.0, -0.001, -0.001, -0.111, -0.011, -0.062, 0.001, -0.017, -0.016, -0.107, -0.179]\n",
      "----------\n",
      "STEP: 31\n",
      "Loss: 0.6000930849696406\n",
      "Model: [-0.233, 0.057, 0.091, -0.01, -0.054, 0.001, 0.001, -0.001, -0.001, -0.001, 0.001, -0.051, 0.001, -0.003, -0.001, -0.005, -0.001, -0.331, -0.002, -0.004, -0.001, -0.023, -0.003, -0.003, -0.006, -0.001, -0.005, -0.001, -0.062, 0.0, -0.004, 0.0, -0.001, -0.001, -0.113, -0.011, -0.063, 0.001, -0.017, -0.016, -0.109, -0.181]\n",
      "----------\n",
      "STEP: 32\n",
      "Loss: 0.5990200669819936\n",
      "Model: [-0.241, 0.058, 0.093, -0.011, -0.056, 0.001, 0.001, -0.001, -0.001, -0.001, 0.001, -0.053, 0.001, -0.004, -0.001, -0.006, -0.001, -0.336, -0.002, -0.004, -0.001, -0.023, -0.003, -0.003, -0.006, -0.001, -0.005, -0.001, -0.063, 0.0, -0.004, 0.0, -0.001, -0.001, -0.115, -0.011, -0.064, 0.001, -0.018, -0.016, -0.11, -0.184]\n",
      "----------\n",
      "STEP: 33\n",
      "Loss: 0.5980256389420352\n",
      "Model: [-0.249, 0.059, 0.095, -0.011, -0.057, 0.001, 0.001, -0.001, -0.001, -0.001, 0.001, -0.054, 0.001, -0.004, -0.001, -0.006, -0.001, -0.34, -0.002, -0.004, -0.001, -0.024, -0.003, -0.003, -0.006, -0.001, -0.005, -0.001, -0.064, 0.0, -0.005, 0.0, -0.001, -0.002, -0.117, -0.011, -0.066, 0.001, -0.018, -0.016, -0.112, -0.186]\n",
      "----------\n",
      "STEP: 34\n",
      "Loss: 0.597103497444477\n",
      "Model: [-0.256, 0.06, 0.097, -0.011, -0.058, 0.001, 0.001, -0.002, -0.002, -0.001, 0.001, -0.055, 0.001, -0.004, -0.001, -0.006, -0.001, -0.344, -0.002, -0.004, -0.001, -0.024, -0.003, -0.003, -0.006, -0.001, -0.005, -0.001, -0.065, 0.0, -0.005, 0.0, -0.001, -0.002, -0.119, -0.011, -0.067, 0.001, -0.018, -0.017, -0.114, -0.189]\n",
      "----------\n",
      "STEP: 35\n",
      "Loss: 0.5962478812676043\n",
      "Model: [-0.263, 0.061, 0.099, -0.011, -0.059, 0.001, 0.001, -0.002, -0.002, -0.001, 0.001, -0.056, 0.001, -0.004, -0.001, -0.006, -0.001, -0.348, -0.002, -0.004, -0.001, -0.025, -0.003, -0.003, -0.006, -0.001, -0.005, -0.001, -0.066, 0.0, -0.005, 0.0, -0.001, -0.002, -0.12, -0.012, -0.068, 0.001, -0.019, -0.017, -0.115, -0.191]\n",
      "----------\n",
      "STEP: 36\n",
      "Loss: 0.5954535217562877\n",
      "Model: [-0.27, 0.062, 0.101, -0.012, -0.061, 0.001, 0.001, -0.002, -0.002, -0.001, 0.001, -0.057, 0.001, -0.004, -0.001, -0.006, -0.001, -0.352, -0.002, -0.004, -0.001, -0.025, -0.003, -0.003, -0.006, -0.001, -0.005, -0.001, -0.066, 0.0, -0.005, 0.0, -0.001, -0.002, -0.122, -0.012, -0.069, 0.001, -0.019, -0.017, -0.117, -0.193]\n",
      "----------\n",
      "STEP: 37\n",
      "Loss: 0.5947155979753049\n",
      "Model: [-0.277, 0.063, 0.103, -0.012, -0.062, 0.001, 0.001, -0.002, -0.002, -0.001, 0.001, -0.059, 0.001, -0.004, -0.001, -0.006, -0.001, -0.356, -0.003, -0.004, -0.001, -0.026, -0.003, -0.003, -0.006, -0.001, -0.005, -0.001, -0.067, 0.0, -0.005, 0.0, -0.001, -0.002, -0.123, -0.012, -0.069, 0.001, -0.019, -0.017, -0.118, -0.195]\n",
      "----------\n",
      "STEP: 38\n",
      "Loss: 0.5940296961622994\n",
      "Model: [-0.283, 0.064, 0.105, -0.012, -0.063, 0.001, 0.001, -0.002, -0.002, -0.001, 0.001, -0.06, 0.001, -0.004, -0.001, -0.006, -0.001, -0.359, -0.003, -0.004, -0.001, -0.026, -0.003, -0.003, -0.006, -0.001, -0.005, -0.001, -0.068, 0.0, -0.005, 0.0, -0.001, -0.002, -0.125, -0.012, -0.07, 0.001, -0.019, -0.018, -0.12, -0.197]\n",
      "----------\n",
      "STEP: 39\n",
      "Loss: 0.5933917730552107\n",
      "Model: [-0.289, 0.065, 0.106, -0.012, -0.064, 0.001, 0.001, -0.002, -0.002, -0.001, 0.001, -0.061, 0.001, -0.004, -0.001, -0.006, -0.001, -0.362, -0.003, -0.004, -0.001, -0.026, -0.003, -0.003, -0.006, -0.001, -0.006, -0.001, -0.068, 0.0, -0.005, 0.0, -0.001, -0.002, -0.126, -0.012, -0.071, 0.001, -0.02, -0.018, -0.121, -0.199]\n",
      "----------\n",
      "STEP: 40\n",
      "Loss: 0.5927981227107537\n",
      "Model: [-0.295, 0.066, 0.108, -0.013, -0.065, 0.001, 0.001, -0.002, -0.002, -0.001, 0.001, -0.062, 0.001, -0.004, -0.001, -0.007, -0.001, -0.365, -0.003, -0.004, -0.001, -0.027, -0.004, -0.004, -0.007, -0.001, -0.006, -0.001, -0.069, 0.0, -0.005, 0.0, -0.001, -0.002, -0.128, -0.013, -0.072, 0.001, -0.02, -0.018, -0.123, -0.201]\n",
      "----------\n",
      "STEP: 41\n",
      "Loss: 0.5922453464684404\n",
      "Model: [-0.301, 0.067, 0.11, -0.013, -0.066, 0.001, 0.001, -0.002, -0.002, -0.002, 0.001, -0.063, 0.001, -0.004, -0.001, -0.007, -0.001, -0.368, -0.003, -0.004, -0.001, -0.027, -0.004, -0.004, -0.007, -0.001, -0.006, -0.001, -0.07, 0.0, -0.005, 0.0, -0.001, -0.002, -0.129, -0.013, -0.073, 0.001, -0.02, -0.018, -0.124, -0.202]\n",
      "----------\n",
      "STEP: 42\n",
      "Loss: 0.5917303257491737\n",
      "Model: [-0.307, 0.068, 0.111, -0.013, -0.067, 0.001, 0.001, -0.002, -0.002, -0.002, 0.001, -0.064, 0.001, -0.004, -0.001, -0.007, -0.001, -0.371, -0.003, -0.004, -0.001, -0.028, -0.004, -0.004, -0.007, -0.001, -0.006, -0.001, -0.07, 0.0, -0.006, 0.0, -0.001, -0.002, -0.13, -0.013, -0.074, 0.001, -0.02, -0.018, -0.125, -0.204]\n",
      "----------\n",
      "STEP: 43\n",
      "Loss: 0.5912501974086154\n",
      "Model: [-0.312, 0.068, 0.113, -0.013, -0.069, 0.001, 0.001, -0.002, -0.002, -0.002, 0.001, -0.065, 0.001, -0.004, -0.001, -0.007, -0.001, -0.374, -0.003, -0.004, -0.001, -0.028, -0.004, -0.004, -0.007, -0.001, -0.006, -0.001, -0.071, 0.0, -0.006, 0.0, -0.001, -0.002, -0.132, -0.013, -0.075, 0.001, -0.021, -0.019, -0.127, -0.205]\n",
      "----------\n",
      "STEP: 44\n",
      "Loss: 0.5908023313937613\n",
      "Model: [-0.317, 0.069, 0.115, -0.013, -0.07, 0.001, 0.001, -0.002, -0.002, -0.002, 0.001, -0.066, 0.001, -0.004, -0.001, -0.007, -0.001, -0.377, -0.003, -0.004, -0.001, -0.028, -0.004, -0.004, -0.007, -0.001, -0.006, -0.001, -0.071, 0.0, -0.006, 0.0, -0.001, -0.002, -0.133, -0.013, -0.075, 0.001, -0.021, -0.019, -0.128, -0.207]\n",
      "----------\n",
      "STEP: 45\n",
      "Loss: 0.5903843104765613\n",
      "Model: [-0.322, 0.07, 0.116, -0.014, -0.071, 0.001, 0.001, -0.002, -0.002, -0.002, 0.001, -0.067, 0.001, -0.005, -0.001, -0.007, -0.001, -0.379, -0.003, -0.004, -0.001, -0.029, -0.004, -0.004, -0.007, -0.001, -0.006, -0.001, -0.072, 0.0, -0.006, 0.0, -0.001, -0.002, -0.134, -0.014, -0.076, 0.001, -0.021, -0.019, -0.129, -0.208]\n",
      "----------\n",
      "STEP: 46\n",
      "Loss: 0.5899939118613238\n",
      "Model: [-0.327, 0.071, 0.118, -0.014, -0.072, 0.001, 0.001, -0.002, -0.002, -0.002, 0.001, -0.068, 0.001, -0.005, -0.001, -0.007, -0.001, -0.381, -0.003, -0.004, -0.001, -0.029, -0.004, -0.004, -0.007, -0.001, -0.006, -0.001, -0.072, 0.0, -0.006, 0.0, -0.001, -0.002, -0.135, -0.014, -0.077, 0.001, -0.021, -0.019, -0.13, -0.209]\n",
      "----------\n",
      "STEP: 47\n",
      "Loss: 0.589629090483217\n",
      "Model: [-0.332, 0.072, 0.119, -0.014, -0.073, 0.001, 0.001, -0.002, -0.002, -0.002, 0.001, -0.069, 0.001, -0.005, -0.001, -0.007, -0.001, -0.384, -0.003, -0.004, -0.001, -0.03, -0.004, -0.004, -0.007, -0.001, -0.006, -0.001, -0.072, 0.0, -0.006, 0.0, -0.001, -0.002, -0.136, -0.014, -0.077, 0.001, -0.022, -0.019, -0.131, -0.211]\n",
      "----------\n",
      "STEP: 48\n",
      "Loss: 0.5892879638336853\n",
      "Model: [-0.337, 0.072, 0.121, -0.014, -0.074, 0.001, 0.001, -0.002, -0.002, -0.002, 0.001, -0.07, 0.001, -0.005, -0.001, -0.007, -0.001, -0.386, -0.003, -0.004, -0.001, -0.03, -0.004, -0.004, -0.007, -0.001, -0.006, -0.001, -0.073, 0.0, -0.006, 0.0, -0.001, -0.002, -0.138, -0.014, -0.078, 0.001, -0.022, -0.019, -0.132, -0.212]\n",
      "----------\n",
      "STEP: 49\n",
      "Loss: 0.5889687981651772\n",
      "Model: [-0.341, 0.073, 0.122, -0.014, -0.075, 0.001, 0.001, -0.002, -0.002, -0.002, 0.001, -0.071, 0.001, -0.005, -0.001, -0.008, -0.001, -0.388, -0.003, -0.004, -0.001, -0.03, -0.004, -0.004, -0.007, -0.001, -0.007, -0.001, -0.073, 0.0, -0.006, 0.0, -0.001, -0.002, -0.139, -0.014, -0.079, 0.001, -0.022, -0.02, -0.133, -0.213]\n",
      "----------\n",
      "STEP: 50\n",
      "Loss: 0.5886699959424969\n",
      "Model: [-0.345, 0.074, 0.124, -0.015, -0.076, 0.001, 0.001, -0.002, -0.002, -0.002, 0.001, -0.072, 0.001, -0.005, -0.001, -0.008, -0.001, -0.39, -0.003, -0.004, -0.001, -0.031, -0.004, -0.004, -0.007, -0.001, -0.007, -0.001, -0.073, 0.0, -0.006, 0.0, -0.001, -0.002, -0.14, -0.015, -0.079, 0.001, -0.022, -0.02, -0.134, -0.214]\n"
     ]
    }
   ],
   "source": [
    "nSteps = 50\n",
    "model = coefs\n",
    "print(f\"BASELINE:  Loss = {LogLoss(toyRDD,model)}\")\n",
    "for idx in range(nSteps):\n",
    "    print(\"----------\")\n",
    "    print(f\"STEP: {idx+1}\")\n",
    "    model = GDUpdate(toyRDD, model)\n",
    "    loss = LogLoss(toyRDD, model)\n",
    "    print(f\"Loss: {loss}\")\n",
    "    print(f\"Model: {[round(w,3) for w in model]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
