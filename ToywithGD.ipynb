{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression on Toy Data Set with Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#pyspark dependencies\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "from pyspark.sql import SQLContext, functions as f\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"toy\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "#setting schema and reading in pre-processed data to pyspark dataframe\n",
    "intFeatures = ['intFeature1','intFeature2','intFeature3','intFeature4']\n",
    "catFeatures = ['catFeature5','catFeature6']\n",
    "outcomeField = [StructField(\"click\", IntegerType(), True)]\n",
    "quantFields = [StructField(f, DoubleType(), True) for f in intFeatures]\n",
    "qualFields = [StructField(f, StringType(), True) for f in catFeatures]\n",
    "schema = StructType(outcomeField + quantFields + qualFields)\n",
    "\n",
    "toyDf = spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(\"toySample/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+--------------------+--------------------+--------------------+-----------+-----------+\n",
      "|click|        intFeature1|         intFeature2|         intFeature3|         intFeature4|catFeature5|catFeature6|\n",
      "+-----+-------------------+--------------------+--------------------+--------------------+-----------+-----------+\n",
      "|    0|0.38044728201922134|  1.0461280017194063|  0.8317161330745142|  0.3659735546106383|   25c83c98|   6f6d9be8|\n",
      "|    1|0.38044728201922134| -1.2072044937875812| -1.0969510532590658|  -0.808690496702659|   25c83c98|   7e0ccccf|\n",
      "|    0|0.38044728201922134| -1.2072044937875812|  1.7753909926499136|  0.3659735546106383|   25c83c98|   fbad5c96|\n",
      "|    0|-1.3933721049834424| -1.2072044937875812|  1.9415838693847296|   1.681697323928138|   25c83c98|   7e0ccccf|\n",
      "|    1|-1.3933721049834424| -1.2072044937875812|  1.1861284542225656|   1.681697323928138|   384874ce|   7e0ccccf|\n",
      "|    1|-0.5064624114821106| -1.2072044937875812|  0.7709669997151446|0.021438776840939814|   25c83c98|   7e0ccccf|\n",
      "|    0|-0.5064624114821106| -0.8792259093197071|  0.8018840847466963|  0.5070332726148404|   43b19349|  NA_Bucket|\n",
      "|    1| 1.2673569755205532| -0.6873707363663946|-0.37664099210799884| 0.20605323600656728|   25c83c98|   fbad5c96|\n",
      "|    0|-1.3933721049834424|-0.16753697894520792| -1.0969510532590658|  0.6332154901527597|   25c83c98|   fe6b92e5|\n",
      "|    1| 0.6659684299852395| 0.23338155706897726|  0.8317161330745142|  0.3659735546106383|   25c83c98|   fbad5c96|\n",
      "|    0|0.38044728201922134|  0.5262942442982196| -0.5076885148317183|  2.1672918197020383|   25c83c98|   7e0ccccf|\n",
      "|    0|0.38044728201922134|  1.8494483761453233| -1.0969510532590658| -1.2942849924765598|   25c83c98|   fbad5c96|\n",
      "|    1|-1.3933721049834424|  1.0461280017194063|  0.8317161330745142|  0.3659735546106383|   25c83c98|   fbad5c96|\n",
      "|    0|-1.3933721049834424| -1.2072044937875812| 0.21262154631934865|0.021438776840939814|   25c83c98|   fbad5c96|\n",
      "|    0|-0.5064624114821106| -1.2072044937875812| -0.5076885148317183|-0.19691378339083973|   43b19349|  NA_Bucket|\n",
      "|    0|0.38044728201922134| -0.8792259093197071| -1.4416475413188234|   1.730586699238479|   25c83c98|  NA_Bucket|\n",
      "|    1|0.38044728201922134| -0.6873707363663946| -1.0969510532590658|  0.3659735546106383|   25c83c98|   7e0ccccf|\n",
      "|    0|-1.3933721049834424|-0.16753697894520792|  0.8317161330745142|  -0.808690496702659|   25c83c98|   7e0ccccf|\n",
      "|    0|0.38044728201922134|  0.2965650170372276|  0.8317161330745142| -0.4641557189329606|   25c83c98|   fe6b92e5|\n",
      "|    0|-1.3933721049834424|  1.0254621375192867|  0.8317161330745142| -1.2942849924765598|   25c83c98|   fe6b92e5|\n",
      "+-----+-------------------+--------------------+--------------------+--------------------+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toyDf.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHotEncoder(dataframe,columns):\n",
    "    '''takes a dataframe and corresponding list of columns\n",
    "    to one-hot encode'''\n",
    "    for c in columns:\n",
    "        # collect unique levels in category\n",
    "        levels = dataframe.select(c).distinct().rdd.flatMap(lambda x: x).collect()\n",
    "        #generate dummy variables and associated values\n",
    "        dummy_vals = [f.when(f.col(c) == level, 1).otherwise(0).alias(\"encoded_\" + level) for level in levels]\n",
    "        #update dataframe with new dummy columns (indicator features)\n",
    "        \n",
    "        dataframe = dataframe.select('*',*dummy_vals)\n",
    "    #drop unencoded categorical columns from dataframe    \n",
    "    dataframe = dataframe.drop(*columns)\n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are now 42 columns\n"
     ]
    }
   ],
   "source": [
    "#encode all categorical columns\n",
    "categories = [c for c in toyDf.columns if 'cat' in c]\n",
    "toy_df_encoded = OneHotEncoder(toyDf,categories)\n",
    "print('there are now ' + str(len(toy_df_encoded.columns)) + ' columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+------------------+------------------+------------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+-------------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+-----------------+----------------+----------------+----------------+----------------+----------------+\n",
      "|click|        intFeature1|       intFeature2|       intFeature3|       intFeature4|encoded_bf9f7f48|encoded_5a3e1872|encoded_65be028e|encoded_2c6b8ded|encoded_89ff5705|encoded_3a136cf2|encoded_43b19349|encoded_afcf7897|encoded_f3474129|encoded_Rare_Bucket|encoded_b2241560|encoded_db844843|encoded_25c83c98|encoded_4f8b7acc|encoded_30903e74|encoded_a93acb09|encoded_384874ce|encoded_f281d2a7|encoded_b706ee81|encoded_0942e0a7|encoded_8c837181|encoded_b0530c50|encoded_d5b7606b|encoded_4cf72387|encoded_229df405|encoded_307e775a|encoded_4ea20c7d|encoded_a9411994|encoded_f1d40cbe|encoded_fbad5c96|encoded_3bf701e7|encoded_NA_Bucket|encoded_f1f2de2d|encoded_6f6d9be8|encoded_13718bbd|encoded_fe6b92e5|encoded_7e0ccccf|\n",
      "+-----+-------------------+------------------+------------------+------------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+-------------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+-----------------+----------------+----------------+----------------+----------------+----------------+\n",
      "|    0|0.38044728201922134|1.0461280017194063|0.8317161330745142|0.3659735546106383|               0|               0|               0|               0|               0|               0|               0|               0|               0|                  0|               0|               0|               1|               0|               0|               0|               0|               0|               0|               0|               0|               0|               0|               0|               0|               0|               0|               0|               0|               0|               0|                0|               0|               1|               0|               0|               0|\n",
      "+-----+-------------------+------------------+------------------+------------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+-------------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+-----------------+----------------+----------------+----------------+----------------+----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#notice sparsity from dummy variables\n",
    "toy_df_encoded.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dataframe to RDD\n",
    "toyRDD = toy_df_encoded.rdd.map(lambda x: (x[0],x[1:])).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting coefficient of the \"bias\" as the mean click rate\n",
    "meanClick = toyRDD.map(lambda x: (x[0])).mean()\n",
    "feature_cols = len(toyRDD.take(1)[0][1])\n",
    "coefs = np.array([meanClick] + [0.0]*(feature_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogLoss(RDD,W):\n",
    "    \"\"\"\n",
    "    augments rdd and returns log loss\n",
    "    - why we augment: add a vector \n",
    "    entry of 1 to correspond with the bias term \n",
    "    so that we can apply the model to the data point \n",
    "    using vector multiplication without the added \n",
    "    step of adding the bias.\n",
    "    \n",
    "    Args:\n",
    "        dataframe - columns (target,features...)\n",
    "        W       - (array) model coefficients with bias at index 0\n",
    "    \n",
    "    Reference\n",
    "        def sigmoid(z):\n",
    "            return 1 / (1 + np.exp(-z))\n",
    "        z = np.dot(X, theta)\n",
    "        h = sigmoid(z)\n",
    "        def loss(h, y):\n",
    "            return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "    \"\"\"\n",
    "    #helper function to compute sigmoid\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    #generate augmented rdd of (features,target)\n",
    "    \n",
    "    augmentedData = RDD.map(lambda x: (np.append([1.0],x[1:]),x[0]))\n",
    "    \n",
    "    log_loss = augmentedData \\\n",
    "    .map(lambda x: (np.dot(x[0],W),x[1])) \\\n",
    "    .map(lambda x: (sigmoid(x[0]),x[1])) \\\n",
    "    .map(lambda x: (-x[1]*np.log(x[0]) - (1-x[1])*np.log(1-x[0]))) \\\n",
    "    .mean()\n",
    "    \n",
    "    return log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7644838394523965"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogLoss(toyRDD,coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = sc.broadcast(toyRDD.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform a single GD step\n",
    "def GDUpdate(RDD, W, learningRate = 0.1):\n",
    "    \"\"\"\n",
    "    Perform one OLS gradient descent step/update.\n",
    "    Args:\n",
    "        dataRDD - records are tuples of (features_array, y)\n",
    "        W       - (array) model coefficients with bias at index 0\n",
    "    Returns:\n",
    "        new_model - (array) updated coefficients, bias at index 0\n",
    "        \n",
    "    Reference: gradient = np.dot(X.T, (h - y)) / num_observations\n",
    "        - see above LogLoss function for definition of h and y\n",
    "    \"\"\"\n",
    "    # add a bias 'feature' of 1 at index 0 and convert to array\n",
    "    \n",
    "    #generate augmented rdd of (features,target)\n",
    "    augmentedData = RDD.map(lambda x: (np.append([1.0],x[1:]),x[0]))\n",
    "    \n",
    "    #helper function to compute sigmoid\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    #calculate gradient\n",
    "    getVals = augmentedData \\\n",
    "            .map(lambda x: (np.dot(x[0],coefs),x[0],x[1])) \\\n",
    "            .map(lambda x: (sigmoid(x[0]),x[1],x[2])) \\\n",
    "            .collect()\n",
    "    \n",
    "    features = []\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    for v in getVals:\n",
    "        features.append(v[1])\n",
    "        predictions.append(v[0])\n",
    "        labels.append(v[2])\n",
    "    \n",
    "    f = np.transpose(features)\n",
    "    l = np.array(labels)\n",
    "    p = np.array(predictions)\n",
    "    \n",
    "    gradient = np.dot(f,(p-l))/N.value\n",
    "    \n",
    "    #apply learning rate to gradient and generate new coefficients\n",
    "    update = np.multiply(gradient,learningRate)\n",
    "    \n",
    "    #original model is the bias + assigned coefficients; update the model with the adjusted coefficients\n",
    "    new_model = W - update\n",
    "    ################## (END) YOUR CODE ################# \n",
    "   \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE:  Loss = 0.7644838394523965\n",
      "----------\n",
      "STEP: 1\n",
      "Loss: 0.7496780805769259\n",
      "Model: [0.248, 0.003, 0.004, -0.0, -0.002, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.002, 0.0, -0.0, -0.0, -0.0, -0.0, -0.02, -0.0, -0.0, -0.0, -0.001, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.004, -0.0, -0.0, -0.0, -0.0, -0.0, -0.006, -0.001, -0.003, 0.0, -0.001, -0.001, -0.006, -0.011]\n",
      "----------\n",
      "STEP: 2\n",
      "Loss: 0.7355282612251448\n",
      "Model: [0.219, 0.006, 0.008, -0.001, -0.004, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.005, 0.0, -0.0, -0.0, -0.0, -0.0, -0.04, -0.0, -0.001, -0.0, -0.002, -0.0, -0.0, -0.001, -0.0, -0.0, -0.0, -0.007, -0.0, -0.0, -0.0, -0.0, -0.0, -0.013, -0.001, -0.007, 0.0, -0.002, -0.002, -0.012, -0.022]\n",
      "----------\n",
      "STEP: 3\n",
      "Loss: 0.7220378343443428\n",
      "Model: [0.19, 0.009, 0.012, -0.001, -0.007, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.007, 0.0, -0.0, -0.0, -0.001, -0.0, -0.06, -0.0, -0.001, -0.0, -0.003, -0.001, -0.0, -0.001, -0.0, -0.001, -0.0, -0.011, -0.0, -0.0, -0.0, -0.0, -0.0, -0.019, -0.002, -0.01, 0.0, -0.003, -0.003, -0.018, -0.033]\n",
      "----------\n",
      "STEP: 4\n",
      "Loss: 0.709209265326325\n",
      "Model: [0.161, 0.012, 0.017, -0.002, -0.009, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.009, 0.0, -0.001, -0.0, -0.001, -0.0, -0.08, -0.0, -0.001, -0.0, -0.004, -0.001, -0.0, -0.001, -0.0, -0.001, -0.0, -0.015, -0.0, -0.001, -0.0, -0.0, -0.0, -0.025, -0.002, -0.014, 0.0, -0.004, -0.004, -0.024, -0.044]\n",
      "----------\n",
      "STEP: 5\n",
      "Loss: 0.6970440169588303\n",
      "Model: [0.132, 0.015, 0.021, -0.002, -0.011, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.011, 0.0, -0.001, -0.0, -0.001, -0.0, -0.1, -0.0, -0.001, -0.0, -0.006, -0.001, -0.001, -0.002, -0.0, -0.001, -0.0, -0.018, -0.0, -0.001, -0.0, -0.0, -0.0, -0.032, -0.003, -0.017, 0.0, -0.005, -0.004, -0.031, -0.054]\n",
      "----------\n",
      "STEP: 6\n",
      "Loss: 0.6855425410124654\n",
      "Model: [0.102, 0.018, 0.025, -0.002, -0.013, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.014, 0.0, -0.001, -0.0, -0.001, -0.0, -0.12, -0.0, -0.002, -0.0, -0.007, -0.001, -0.001, -0.002, -0.0, -0.001, -0.0, -0.022, -0.0, -0.001, -0.0, -0.0, -0.0, -0.038, -0.003, -0.021, 0.0, -0.006, -0.005, -0.037, -0.065]\n",
      "----------\n",
      "STEP: 7\n",
      "Loss: 0.6747042765762238\n",
      "Model: [0.073, 0.021, 0.029, -0.003, -0.016, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.016, 0.0, -0.001, -0.0, -0.002, -0.0, -0.14, -0.001, -0.002, -0.0, -0.008, -0.001, -0.001, -0.002, -0.0, -0.001, -0.0, -0.026, -0.0, -0.001, -0.0, -0.0, -0.0, -0.045, -0.004, -0.024, 0.0, -0.007, -0.006, -0.043, -0.076]\n",
      "----------\n",
      "STEP: 8\n",
      "Loss: 0.6645276551528624\n",
      "Model: [0.044, 0.024, 0.033, -0.003, -0.018, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.018, 0.0, -0.001, -0.0, -0.002, -0.0, -0.16, -0.001, -0.002, -0.0, -0.009, -0.001, -0.001, -0.002, -0.0, -0.002, -0.0, -0.029, -0.0, -0.001, -0.0, -0.0, -0.0, -0.051, -0.004, -0.028, 0.0, -0.007, -0.007, -0.049, -0.087]\n",
      "----------\n",
      "STEP: 9\n",
      "Loss: 0.6550101124236477\n",
      "Model: [0.015, 0.027, 0.037, -0.004, -0.02, 0.0, 0.0, -0.0, -0.0, -0.001, 0.0, -0.021, 0.0, -0.001, -0.0, -0.002, -0.0, -0.18, -0.001, -0.003, -0.0, -0.01, -0.002, -0.001, -0.003, -0.0, -0.002, -0.0, -0.033, -0.0, -0.001, -0.0, -0.0, -0.0, -0.057, -0.005, -0.031, 0.0, -0.008, -0.008, -0.055, -0.098]\n",
      "----------\n",
      "STEP: 10\n",
      "Loss: 0.6461481064929523\n",
      "Model: [-0.014, 0.03, 0.041, -0.004, -0.022, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.023, 0.0, -0.002, -0.0, -0.002, -0.0, -0.2, -0.001, -0.003, -0.0, -0.011, -0.002, -0.001, -0.003, -0.0, -0.002, -0.0, -0.037, -0.0, -0.002, -0.0, -0.0, -0.001, -0.064, -0.005, -0.035, 0.0, -0.009, -0.009, -0.061, -0.109]\n",
      "----------\n",
      "STEP: 11\n",
      "Loss: 0.6379371423293864\n",
      "Model: [-0.043, 0.033, 0.045, -0.004, -0.025, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.025, 0.0, -0.002, -0.0, -0.003, -0.0, -0.22, -0.001, -0.003, -0.0, -0.012, -0.002, -0.001, -0.003, -0.0, -0.002, -0.0, -0.04, -0.0, -0.002, -0.0, -0.0, -0.001, -0.07, -0.006, -0.038, 0.0, -0.01, -0.01, -0.067, -0.12]\n",
      "----------\n",
      "STEP: 12\n",
      "Loss: 0.6303718020341901\n",
      "Model: [-0.073, 0.036, 0.05, -0.005, -0.027, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.027, 0.0, -0.002, -0.0, -0.003, -0.0, -0.24, -0.001, -0.004, -0.0, -0.013, -0.002, -0.001, -0.004, -0.0, -0.003, -0.0, -0.044, -0.0, -0.002, -0.0, -0.0, -0.001, -0.076, -0.006, -0.042, 0.0, -0.011, -0.011, -0.073, -0.131]\n",
      "----------\n",
      "STEP: 13\n",
      "Loss: 0.6234457804913223\n",
      "Model: [-0.102, 0.039, 0.054, -0.005, -0.029, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.03, 0.0, -0.002, -0.0, -0.003, -0.0, -0.26, -0.001, -0.004, -0.0, -0.014, -0.002, -0.001, -0.004, -0.0, -0.003, -0.0, -0.048, -0.0, -0.002, -0.0, -0.0, -0.001, -0.083, -0.007, -0.045, 0.0, -0.012, -0.011, -0.079, -0.142]\n",
      "----------\n",
      "STEP: 14\n",
      "Loss: 0.6171519258888666\n",
      "Model: [-0.131, 0.042, 0.058, -0.006, -0.031, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.032, 0.0, -0.002, -0.0, -0.003, -0.0, -0.28, -0.001, -0.004, -0.0, -0.015, -0.002, -0.002, -0.004, -0.0, -0.003, -0.0, -0.051, -0.0, -0.002, -0.0, -0.0, -0.001, -0.089, -0.007, -0.048, 0.0, -0.013, -0.012, -0.085, -0.153]\n",
      "----------\n",
      "STEP: 15\n",
      "Loss: 0.6114822845492377\n",
      "Model: [-0.16, 0.045, 0.062, -0.006, -0.034, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.034, 0.0, -0.002, -0.0, -0.004, -0.0, -0.3, -0.001, -0.004, -0.001, -0.017, -0.003, -0.002, -0.005, -0.0, -0.003, -0.0, -0.055, -0.0, -0.002, -0.0, -0.001, -0.001, -0.096, -0.008, -0.052, 0.0, -0.014, -0.013, -0.092, -0.163]\n",
      "----------\n",
      "STEP: 16\n",
      "Loss: 0.6064281494668092\n",
      "Model: [-0.189, 0.049, 0.066, -0.007, -0.036, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.036, 0.0, -0.002, -0.0, -0.004, -0.0, -0.32, -0.001, -0.005, -0.001, -0.018, -0.003, -0.002, -0.005, -0.0, -0.003, -0.0, -0.059, -0.0, -0.003, -0.0, -0.001, -0.001, -0.102, -0.008, -0.055, 0.0, -0.015, -0.014, -0.098, -0.174]\n",
      "----------\n",
      "STEP: 17\n",
      "Loss: 0.601980111926454\n",
      "Model: [-0.218, 0.052, 0.07, -0.007, -0.038, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.039, 0.0, -0.003, -0.0, -0.004, -0.0, -0.34, -0.001, -0.005, -0.001, -0.019, -0.003, -0.002, -0.005, -0.0, -0.004, -0.0, -0.063, -0.0, -0.003, -0.0, -0.001, -0.001, -0.108, -0.009, -0.059, 0.0, -0.016, -0.015, -0.104, -0.185]\n",
      "----------\n",
      "STEP: 18\n",
      "Loss: 0.598128115564719\n",
      "Model: [-0.247, 0.055, 0.074, -0.007, -0.04, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.041, 0.0, -0.003, -0.0, -0.004, -0.0, -0.36, -0.001, -0.005, -0.001, -0.02, -0.003, -0.002, -0.006, -0.0, -0.004, -0.0, -0.066, -0.0, -0.003, -0.0, -0.001, -0.001, -0.115, -0.01, -0.062, 0.0, -0.017, -0.016, -0.11, -0.196]\n",
      "----------\n",
      "STEP: 19\n",
      "Loss: 0.5948615122364332\n",
      "Model: [-0.277, 0.058, 0.078, -0.008, -0.043, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.043, 0.0, -0.003, -0.001, -0.005, -0.001, -0.38, -0.002, -0.006, -0.001, -0.021, -0.003, -0.002, -0.006, -0.001, -0.004, -0.001, -0.07, -0.0, -0.003, -0.0, -0.001, -0.001, -0.121, -0.01, -0.066, 0.0, -0.018, -0.017, -0.116, -0.207]\n",
      "----------\n",
      "STEP: 20\n",
      "Loss: 0.5921691190624924\n",
      "Model: [-0.306, 0.061, 0.083, -0.008, -0.045, 0.0, 0.0, -0.001, -0.001, -0.001, 0.0, -0.046, 0.0, -0.003, -0.001, -0.005, -0.001, -0.4, -0.002, -0.006, -0.001, -0.022, -0.003, -0.002, -0.006, -0.001, -0.004, -0.001, -0.074, -0.0, -0.003, -0.0, -0.001, -0.001, -0.127, -0.011, -0.069, 0.0, -0.019, -0.018, -0.122, -0.218]\n"
     ]
    }
   ],
   "source": [
    "nSteps = 20\n",
    "model = coefs\n",
    "print(f\"BASELINE:  Loss = {LogLoss(toyRDD,model)}\")\n",
    "for idx in range(nSteps):\n",
    "    print(\"----------\")\n",
    "    print(f\"STEP: {idx+1}\")\n",
    "    model = GDUpdate(toyRDD, model)\n",
    "    loss = LogLoss(toyRDD, model)\n",
    "    print(f\"Loss: {loss}\")\n",
    "    print(f\"Model: {[round(w,3) for w in model]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
